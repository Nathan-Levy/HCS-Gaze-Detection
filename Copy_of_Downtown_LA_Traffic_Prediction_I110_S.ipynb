{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nathan-Levy/HCS-Gaze-Detection/blob/main/Copy_of_Downtown_LA_Traffic_Prediction_I110_S.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vk836ar5Aja7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fD_cEQmBA7y6"
      },
      "outputs": [],
      "source": [
        "controller_data_test = pd.read_csv('Combined flows test.csv')\n",
        "controller_data_test.dropna(how='all', inplace=True)\n",
        "\n",
        "controller_data_train = pd.read_csv('Combined flows train.csv')\n",
        "controller_data_train.dropna(how='all', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBPV-xdWBFGZ",
        "outputId": "f4751fa2-c68d-4f76-b695-8d170646e722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                     MADOR Flow (Veh/5 Minutes)  THIRD Flow (Veh/5 Minutes)  \\\n",
            "5 Minutes                                                                     \n",
            "2018-06-04 00:00:00                         116                         179   \n",
            "2018-06-04 00:05:00                         119                         168   \n",
            "2018-06-04 00:10:00                          88                         141   \n",
            "2018-06-04 00:15:00                          81                         130   \n",
            "2018-06-04 00:20:00                          84                         166   \n",
            "...                                         ...                         ...   \n",
            "2018-07-01 23:35:00                         153                         143   \n",
            "2018-07-01 23:40:00                         152                         139   \n",
            "2018-07-01 23:45:00                         139                         136   \n",
            "2018-07-01 23:50:00                         149                         132   \n",
            "2018-07-01 23:55:00                         136                         113   \n",
            "\n",
            "                     11TH Flow (Veh/5 Minutes)  ADAMS Flow (Veh/5 Minutes)  \\\n",
            "5 Minutes                                                                    \n",
            "2018-06-04 00:00:00                        281                         208   \n",
            "2018-06-04 00:05:00                        338                         292   \n",
            "2018-06-04 00:10:00                        287                         358   \n",
            "2018-06-04 00:15:00                        238                         280   \n",
            "2018-06-04 00:20:00                        270                         214   \n",
            "...                                        ...                         ...   \n",
            "2018-07-01 23:35:00                        446                         454   \n",
            "2018-07-01 23:40:00                        382                         385   \n",
            "2018-07-01 23:45:00                        422                         390   \n",
            "2018-07-01 23:50:00                        349                         389   \n",
            "2018-07-01 23:55:00                        299                         329   \n",
            "\n",
            "                     KING BLVD Flow (Veh/5 Minutes)  \n",
            "5 Minutes                                            \n",
            "2018-06-04 00:00:00                             213  \n",
            "2018-06-04 00:05:00                             254  \n",
            "2018-06-04 00:10:00                             301  \n",
            "2018-06-04 00:15:00                             265  \n",
            "2018-06-04 00:20:00                             218  \n",
            "...                                             ...  \n",
            "2018-07-01 23:35:00                             400  \n",
            "2018-07-01 23:40:00                             359  \n",
            "2018-07-01 23:45:00                             340  \n",
            "2018-07-01 23:50:00                             292  \n",
            "2018-07-01 23:55:00                             284  \n",
            "\n",
            "[8062 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "controller_data_train[\"5 Minutes\"] = pd.to_datetime(controller_data_train[\"5 Minutes\"])\n",
        "controller_data_train.set_index(\"5 Minutes\", inplace=True)\n",
        "\n",
        "# Keep only the relevant column\n",
        "time_flow_train = controller_data_train[['MADOR Flow (Veh/5 Minutes)', 'THIRD Flow (Veh/5 Minutes)', '11TH Flow (Veh/5 Minutes)', 'ADAMS Flow (Veh/5 Minutes)', 'KING BLVD Flow (Veh/5 Minutes)']]\n",
        "\n",
        "controller_data_test[\"5 Minutes\"] = pd.to_datetime(controller_data_test[\"5 Minutes\"])\n",
        "controller_data_test.set_index(\"5 Minutes\", inplace=True)\n",
        "\n",
        "# Keep only the relevant column\n",
        "time_flow_test = controller_data_test[['MADOR Flow (Veh/5 Minutes)', 'THIRD Flow (Veh/5 Minutes)', '11TH Flow (Veh/5 Minutes)', 'ADAMS Flow (Veh/5 Minutes)', 'KING BLVD Flow (Veh/5 Minutes)']]\n",
        "\n",
        "print(time_flow_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9hoJmCZCpLJ"
      },
      "outputs": [],
      "source": [
        "# Normalise\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "flow_train_scaled = scaler.fit_transform(time_flow_train)\n",
        "flow_test_scaled = scaler.transform(time_flow_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thA-2YsLCsKR"
      },
      "outputs": [],
      "source": [
        "# Train and validation split\n",
        "flow_train, flow_test, = flow_train_scaled, flow_test_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpgrd81ir5US",
        "outputId": "a408f9d0-3aa0-4256-a413-3608371ab7ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training model with look_back = 12...\n",
            "Epoch 1/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - loss: 0.0231 - val_loss: 0.0034\n",
            "Epoch 2/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0023 - val_loss: 0.0024\n",
            "Epoch 3/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0018 - val_loss: 0.0022\n",
            "Epoch 4/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0021\n",
            "Epoch 5/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 6/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0019\n",
            "Epoch 7/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 8/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 9/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 10/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 11/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 12/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 13/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0016\n",
            "Epoch 14/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0016\n",
            "Epoch 15/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0016\n",
            "Epoch 16/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0016\n",
            "Epoch 17/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0016\n",
            "Epoch 18/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0015\n",
            "Epoch 19/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0016\n",
            "Epoch 20/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0015\n",
            "\u001b[1m567/567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0188 - val_loss: 0.0041\n",
            "Epoch 2/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0036\n",
            "Epoch 3/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0025 - val_loss: 0.0031\n",
            "Epoch 4/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0031\n",
            "Epoch 5/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 6/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 7/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 0.0030\n",
            "Epoch 8/20\n",
            "\u001b[1m1134/1134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 0.0031\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Look-Back: 12 → MAE: 30.1703, MRE: 8.93%, RMSE: 41.6570\n",
            "\n",
            "Training model with look_back = 288...\n",
            "Epoch 1/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 53ms/step - loss: 0.0466 - val_loss: 0.0392\n",
            "Epoch 2/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 51ms/step - loss: 0.0359 - val_loss: 0.0163\n",
            "Epoch 3/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 51ms/step - loss: 0.0114 - val_loss: 0.0128\n",
            "Epoch 4/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 50ms/step - loss: 0.0080 - val_loss: 0.0094\n",
            "Epoch 5/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 51ms/step - loss: 0.0072 - val_loss: 0.0086\n",
            "Epoch 6/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 51ms/step - loss: 0.0070 - val_loss: 0.0114\n",
            "Epoch 7/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 51ms/step - loss: 0.0069 - val_loss: 0.0077\n",
            "Epoch 8/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 51ms/step - loss: 0.0064 - val_loss: 0.0092\n",
            "Epoch 9/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 50ms/step - loss: 0.0059 - val_loss: 0.0072\n",
            "Epoch 10/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 50ms/step - loss: 0.0052 - val_loss: 0.0075\n",
            "Epoch 11/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 51ms/step - loss: 0.0049 - val_loss: 0.0087\n",
            "Epoch 12/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 50ms/step - loss: 0.0051 - val_loss: 0.0067\n",
            "Epoch 13/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 50ms/step - loss: 0.0045 - val_loss: 0.0069\n",
            "Epoch 14/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 50ms/step - loss: 0.0044 - val_loss: 0.0065\n",
            "Epoch 15/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 50ms/step - loss: 0.0043 - val_loss: 0.0085\n",
            "Epoch 16/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 50ms/step - loss: 0.0058 - val_loss: 0.0064\n",
            "Epoch 17/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 50ms/step - loss: 0.0044 - val_loss: 0.0062\n",
            "Epoch 18/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 50ms/step - loss: 0.0039 - val_loss: 0.0066\n",
            "Epoch 19/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 51ms/step - loss: 0.0039 - val_loss: 0.0061\n",
            "Epoch 20/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 50ms/step - loss: 0.0038 - val_loss: 0.0084\n",
            "\u001b[1m558/558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.0848 - val_loss: 0.0069\n",
            "Epoch 2/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0065\n",
            "Epoch 3/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0063\n",
            "Epoch 4/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0040 - val_loss: 0.0060\n",
            "Epoch 5/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0037 - val_loss: 0.0063\n",
            "Epoch 6/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0036 - val_loss: 0.0058\n",
            "Epoch 7/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0059\n",
            "Epoch 8/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0060\n",
            "Epoch 9/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0058\n",
            "Epoch 10/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0057\n",
            "Epoch 11/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0034 - val_loss: 0.0060\n",
            "Epoch 12/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0058\n",
            "Epoch 13/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0057\n",
            "Epoch 14/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0061\n",
            "Epoch 15/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0033 - val_loss: 0.0057\n",
            "Epoch 16/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0056\n",
            "Epoch 17/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0059\n",
            "Epoch 18/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0059\n",
            "Epoch 19/20\n",
            "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0057\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Look-Back: 288 → MAE: 38.5866, MRE: 11.58%, RMSE: 55.3703\n",
            "\n",
            "Training model with look_back = 864...\n",
            "Epoch 1/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 147ms/step - loss: 0.0494 - val_loss: 0.0404\n",
            "Epoch 2/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 138ms/step - loss: 0.0397 - val_loss: 0.0402\n",
            "Epoch 3/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 138ms/step - loss: 0.0394 - val_loss: 0.0396\n",
            "Epoch 4/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 138ms/step - loss: 0.0389 - val_loss: 0.0400\n",
            "Epoch 5/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 138ms/step - loss: 0.0389 - val_loss: 0.0354\n",
            "Epoch 6/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 138ms/step - loss: 0.0363 - val_loss: 0.0226\n",
            "Epoch 7/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 138ms/step - loss: 0.0161 - val_loss: 0.0129\n",
            "Epoch 8/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 138ms/step - loss: 0.0105 - val_loss: 0.0122\n",
            "Epoch 9/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 139ms/step - loss: 0.0099 - val_loss: 0.0122\n",
            "Epoch 10/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 138ms/step - loss: 0.0093 - val_loss: 0.0099\n",
            "Epoch 11/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 138ms/step - loss: 0.0092 - val_loss: 0.0116\n",
            "Epoch 12/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 138ms/step - loss: 0.0082 - val_loss: 0.0117\n",
            "Epoch 13/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 138ms/step - loss: 0.0078 - val_loss: 0.0091\n",
            "Epoch 14/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 138ms/step - loss: 0.0073 - val_loss: 0.0095\n",
            "Epoch 15/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 138ms/step - loss: 0.0072 - val_loss: 0.0087\n",
            "Epoch 16/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 139ms/step - loss: 0.0069 - val_loss: 0.0086\n",
            "Epoch 17/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 138ms/step - loss: 0.0066 - val_loss: 0.0081\n",
            "Epoch 18/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 138ms/step - loss: 0.0064 - val_loss: 0.0092\n",
            "Epoch 19/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 138ms/step - loss: 0.0064 - val_loss: 0.0076\n",
            "Epoch 20/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 138ms/step - loss: 0.0062 - val_loss: 0.0086\n",
            "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 19ms/step\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0732 - val_loss: 0.0100\n",
            "Epoch 2/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0084\n",
            "Epoch 3/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0078\n",
            "Epoch 4/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0071\n",
            "Epoch 5/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0071\n",
            "Epoch 6/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0071\n",
            "Epoch 7/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0067\n",
            "Epoch 8/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0067\n",
            "Epoch 9/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0065\n",
            "Epoch 10/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0063\n",
            "Epoch 11/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0066\n",
            "Epoch 12/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0067\n",
            "Epoch 13/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0064\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Look-Back: 864 → MAE: 41.9602, MRE: 12.84%, RMSE: 59.1786\n",
            "\n",
            "Training model with look_back = 2016...\n",
            "Epoch 1/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 343ms/step - loss: 0.0491 - val_loss: 0.0400\n",
            "Epoch 2/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 322ms/step - loss: 0.0398 - val_loss: 0.0401\n",
            "Epoch 3/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 321ms/step - loss: 0.0395 - val_loss: 0.0391\n",
            "Epoch 4/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 322ms/step - loss: 0.0395 - val_loss: 0.0398\n",
            "Epoch 5/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 322ms/step - loss: 0.0396 - val_loss: 0.0396\n",
            "Epoch 6/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 322ms/step - loss: 0.0397 - val_loss: 0.0400\n",
            "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 49ms/step\n",
            "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0944 - val_loss: 0.0088\n",
            "Epoch 2/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0055 - val_loss: 0.0078\n",
            "Epoch 3/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0051 - val_loss: 0.0075\n",
            "Epoch 4/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0049 - val_loss: 0.0076\n",
            "Epoch 5/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0070\n",
            "Epoch 6/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0070\n",
            "Epoch 7/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0070\n",
            "Epoch 8/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0066\n",
            "Epoch 9/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0068\n",
            "Epoch 10/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0068\n",
            "Epoch 11/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0064\n",
            "Epoch 12/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0041 - val_loss: 0.0064\n",
            "Epoch 13/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0040 - val_loss: 0.0063\n",
            "Epoch 14/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0041 - val_loss: 0.0065\n",
            "Epoch 15/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0039 - val_loss: 0.0061\n",
            "Epoch 16/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0039 - val_loss: 0.0063\n",
            "Epoch 17/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0038 - val_loss: 0.0065\n",
            "Epoch 18/20\n",
            "\u001b[1m1008/1008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0037 - val_loss: 0.0061\n",
            "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Look-Back: 2016 → MAE: 39.8021, MRE: 11.78%, RMSE: 56.3834\n",
            "\n",
            "Optimal Look-Back: 12 with lowest MAE: 30.1703\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define look-back values to test (1 hour, 1 day, 3 days, 1 week)\n",
        "look_back_values = [12, 288, 864, 2016]\n",
        "\n",
        "# Dictionary to store evaluation results\n",
        "results = {}\n",
        "\n",
        "# Function to create dataset for prediction\n",
        "def create_dataset(dataset, look_back):\n",
        "    X, y = [], []\n",
        "    for i in range(len(dataset) - look_back):\n",
        "        X.append(dataset[i:(i + look_back), :])  # Past 'look_back' time steps as input\n",
        "        y.append(dataset[i + look_back, :])  # Predict next time step\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Iterate over different look-back values\n",
        "for look_back in look_back_values:\n",
        "    print(f\"\\nTraining model with look_back = {look_back}...\")\n",
        "\n",
        "    # Prepare dataset\n",
        "    X_train, y_train = create_dataset(flow_train, look_back)\n",
        "    X_test, y_test = create_dataset(flow_test, look_back)\n",
        "\n",
        "    # Reshape for LSTM input\n",
        "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2])\n",
        "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2])\n",
        "\n",
        "    input_layer = keras.layers.Input(shape=(look_back, 5))\n",
        "    encoded = keras.layers.LSTM(64, activation='tanh', return_sequences=True)(input_layer)\n",
        "    encoded = keras.layers.LSTM(32, activation='tanh', return_sequences=False)(encoded)\n",
        "\n",
        "    decoded = keras.layers.RepeatVector(look_back)(encoded)\n",
        "    decoded = keras.layers.LSTM(64, activation='tanh', return_sequences=True)(decoded)\n",
        "    decoded = keras.layers.TimeDistributed(layers.Dense(5, activation='linear'))(decoded)\n",
        "\n",
        "    # Define autoencoder\n",
        "    autoencoder = keras.models.Model(inputs=input_layer, outputs=decoded)\n",
        "\n",
        "    # Compile autoencoder\n",
        "    optimizer = keras.optimizers.Adam(clipnorm=1.0, learning_rate=0.0005)\n",
        "    autoencoder.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "    # Train autoencoder\n",
        "    autoencoder.fit(X_train, X_train, epochs=20, batch_size=16, validation_data=(X_test, X_test),\n",
        "                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)])\n",
        "\n",
        "    # Extract the encoder\n",
        "    encoder = keras.models.Model(inputs=input_layer, outputs=encoded)\n",
        "\n",
        "    # Generate encoded features\n",
        "    encoded_features_train = encoder.predict(X_train)\n",
        "    encoded_features_test = encoder.predict(X_test)\n",
        "\n",
        "    prediction_model = keras.models.Sequential([\n",
        "        keras.layers.Dense(16, activation='relu', input_dim=encoded_features_train.shape[1]),\n",
        "        keras.layers.Dense(8, activation='relu'),\n",
        "        keras.layers.Dense(5, activation='linear')  # Predicting next time step\n",
        "    ])\n",
        "\n",
        "    # Compile predictor\n",
        "    prediction_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    # Train predictor\n",
        "    prediction_model.fit(encoded_features_train, y_train, epochs=20, batch_size=16, validation_data=(encoded_features_test, y_test),\n",
        "                         callbacks=[EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)])\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = prediction_model.predict(encoded_features_test)\n",
        "\n",
        "    # Inverse transform predictions (if data was normalized)\n",
        "    y_pred_original = scaler.inverse_transform(y_pred)\n",
        "    y_test_original = scaler.inverse_transform(y_test)\n",
        "\n",
        "    # Step 3: Compute Evaluation Metrics\n",
        "    def mean_absolute_error(y_true, y_pred):\n",
        "        return np.mean(np.abs(y_true - y_pred))\n",
        "\n",
        "    def mean_relative_error(y_true, y_pred):\n",
        "        return np.mean(np.abs(y_true - y_pred) / np.abs(y_true)) * 100  # Percentage\n",
        "\n",
        "    def root_mean_squared_error(y_true, y_pred):\n",
        "        return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
        "\n",
        "    mae = mean_absolute_error(y_test_original, y_pred_original)\n",
        "    mre = mean_relative_error(y_test_original, y_pred_original)\n",
        "    rmse = root_mean_squared_error(y_test_original, y_pred_original)\n",
        "\n",
        "    # Store results\n",
        "    results[look_back] = {'MAE': mae, 'MRE': mre, 'RMSE': rmse}\n",
        "\n",
        "    print(f\"Look-Back: {look_back} → MAE: {mae:.4f}, MRE: {mre:.2f}%, RMSE: {rmse:.4f}\")\n",
        "\n",
        "best_look_back = min(results, key=lambda x: results[x]['MAE'])  # Choose based on MAE\n",
        "print(f\"\\nOptimal Look-Back: {best_look_back} with lowest MAE: {results[best_look_back]['MAE']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEQUkX6LsGgi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNn3v7TVT3LOqG3UlXLo+bX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}